{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Optimization\n",
    "\n",
    "In value methods, we find a function $Q(s, A)$, and use a greedy policy or $\\epsilon$-greedy policy. In policy methods, we directly parametrize the policy. Actor-Critic learns both value and policy.\n",
    "Policy methods can learn optimal stochastic policy.\n",
    "\n",
    "We want to optimize $J(\\theta) = \\sum_s \\mu_{\\pi_{\\theta}}(s)v_{\\pi_{\\theta}}(s)$, where $\\mu(s)$ is the probability of being in state $s$ in the long run.\n",
    "\n",
    "This is an optimization problem for $J(\\theta)$. Some approaches do not use gradient: hill climbing, genetic algorithms.\n",
    "\n",
    "This [*spinning-up tutorial*](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html) describes the vanilla policy gradient algorithm in-depth with a sample implementation.\n",
    "\n",
    "Youtube has a paper on [*REINFORCE and exploration*](https://arxiv.org/pdf/1812.02353.pdf)\n",
    "\n",
    "Improvements to the vanilla policy gradient method includes:\n",
    "1. *reward to go* (For each transition, only sum up the rewards that come after this action as weight)\n",
    "2. *baseline* We can add/subtract a term that only depends on the state. Such function is called a baseline. A common choice is the on-policy value function $V^{\\pi}(s_t)$. (Subtract baseline from reward-to-go)\n",
    "\n",
    "Algorithms like VPG, TRPO, PPO, and A2C approximates $V_{\\phi}$ by using gradient descent on: $\\phi_k = \\arg \\min_{\\phi} \\underset{s_t, \\hat{R}_t \\sim \\pi_k}{E}{\\left( V_{\\phi}(s_t) - \\hat{R}_t \\right)^2}$\n",
    "\n",
    "[Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438) goes into depth about different choices of $\\Phi_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('halite': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5403c2f46487192050ca51a2569a732e9e397cd03869abc4ffc9610a65d22dfa"
    }
   },
   "name": "Python 3.8.5 64-bit ('halite': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}